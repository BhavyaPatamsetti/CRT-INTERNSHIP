{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nfrom sklearn.datasets import load_files\n\nimport time\n\n# Text cleaning and precprcessing\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-18T08:02:36.078153Z","iopub.execute_input":"2023-05-18T08:02:36.078843Z","iopub.status.idle":"2023-05-18T08:02:36.084844Z","shell.execute_reply.started":"2023-05-18T08:02:36.078797Z","shell.execute_reply":"2023-05-18T08:02:36.083450Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"X, y = [], []\nemail = load_files(\"../input/enron-spam/enron1\")\nX = np.append(X, email.data)\ny = np.append(y, email.target)    ","metadata":{"execution":{"iopub.status.busy":"2023-05-18T08:02:37.347912Z","iopub.execute_input":"2023-05-18T08:02:37.348421Z","iopub.status.idle":"2023-05-18T08:02:54.423750Z","shell.execute_reply.started":"2023-05-18T08:02:37.348350Z","shell.execute_reply":"2023-05-18T08:02:54.422483Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Let's create Dataframe with text and target feature","metadata":{}},{"cell_type":"code","source":"df_all = pd.DataFrame(columns=['text', 'target'])\ndf_all['text'] = [x for x in X]\ndf_all['target'] = [t for t in y]","metadata":{"execution":{"iopub.status.busy":"2023-05-18T08:02:56.904802Z","iopub.execute_input":"2023-05-18T08:02:56.905218Z","iopub.status.idle":"2023-05-18T08:02:57.054597Z","shell.execute_reply.started":"2023-05-18T08:02:56.905183Z","shell.execute_reply":"2023-05-18T08:02:57.053568Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df_all","metadata":{"execution":{"iopub.status.busy":"2023-05-18T08:02:58.109086Z","iopub.execute_input":"2023-05-18T08:02:58.109662Z","iopub.status.idle":"2023-05-18T08:02:58.136930Z","shell.execute_reply.started":"2023-05-18T08:02:58.109609Z","shell.execute_reply":"2023-05-18T08:02:58.135675Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                   text  target\n0     b'Subject: nesa / hea \\' s 24 th annual meetin...     0.0\n1     b'Subject: meter 1431 - nov 1999\\r\\ndaren -\\r\\...     0.0\n2     b\"Subject: investor here .\\r\\nfrom : mr . rich...     1.0\n3     b\"Subject: hi paliourg all available meds . av...     1.0\n4     b'Subject: january nominations at shell deer p...     0.0\n...                                                 ...     ...\n5167  b\"Subject: check it out\\r\\nyou have to know th...     1.0\n5168  b'Subject: re : noms / actual vols for 5 / 18 ...     0.0\n5169  b'Subject: oct prod est - revision\\r\\ndaren ,\\...     0.0\n5170  b'Subject: enron / hpl actuals for february 21...     0.0\n5171  b'Subject: fw : [ fwd : two prayer requests ]\\...     0.0\n\n[5172 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b'Subject: nesa / hea \\' s 24 th annual meetin...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b'Subject: meter 1431 - nov 1999\\r\\ndaren -\\r\\...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b\"Subject: investor here .\\r\\nfrom : mr . rich...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b\"Subject: hi paliourg all available meds . av...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b'Subject: january nominations at shell deer p...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5167</th>\n      <td>b\"Subject: check it out\\r\\nyou have to know th...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5168</th>\n      <td>b'Subject: re : noms / actual vols for 5 / 18 ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5169</th>\n      <td>b'Subject: oct prod est - revision\\r\\ndaren ,\\...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5170</th>\n      <td>b'Subject: enron / hpl actuals for february 21...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5171</th>\n      <td>b'Subject: fw : [ fwd : two prayer requests ]\\...</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5172 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_X = df_all.drop(['target'], axis=1)\ndf_y = df_all['target']","metadata":{"execution":{"iopub.status.busy":"2023-05-18T08:02:59.459344Z","iopub.execute_input":"2023-05-18T08:02:59.459771Z","iopub.status.idle":"2023-05-18T08:02:59.468050Z","shell.execute_reply.started":"2023-05-18T08:02:59.459732Z","shell.execute_reply":"2023-05-18T08:02:59.466448Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"stemmer = PorterStemmer()\nlemmatizer = WordNetLemmatizer()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T08:03:01.083870Z","iopub.execute_input":"2023-05-18T08:03:01.084372Z","iopub.status.idle":"2023-05-18T08:03:01.089849Z","shell.execute_reply.started":"2023-05-18T08:03:01.084328Z","shell.execute_reply":"2023-05-18T08:03:01.088405Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\n\n# Create corpus\ncorpus = []\nfor i in range(0, len(df_X)):\n    # Remove special symbols\n    review = re.sub(r'\\\\r\\\\n', ' ', str(df_X['text'][i]))\n    # Remove all symbols except letters\n    review = re.sub('[^a-zA-Z]', ' ', review)\n    # Replacing all gaps with spaces \n    review = re.sub(r'\\s+', ' ', review)                    \n    # Remove 'b' in the beginning of each text\n    review = re.sub(r'^b\\s+', '', review)       \n\n    review = review.lower()\n    review = review.split()\n    review = [stemmer.stem(word) for word in review if word not in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n#tf = TfidfVectorizer()\n\n# Creating the Bag of Words model\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\nX = cv.fit_transform(corpus).toarray()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting data on train and test dataset\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y,  random_state=9, test_size=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix\n\nmodel = MultinomialNB().fit(X_train, y_train)\npred = model.predict(X_test)\n\naccuracy = accuracy_score(y_test, pred)\nprecision = precision_score(y_test, pred)\nrecall = recall_score(y_test, pred)\nconf_m = confusion_matrix(y_test, pred)\n\nprint(f\"accuracy: %.3f\" %accuracy)\nprint(f\"precision: %.3f\" %precision)\nprint(f\"recall: %.3f\" %recall)\nprint(f\"confusion matrix: \")\nprint(conf_m)\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}